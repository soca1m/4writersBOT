"""
–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LLM —á–µ—Ä–µ–∑ OpenRouter
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª—é–±—ã–µ –º–æ–¥–µ–ª–∏: Claude, GPT, Gemini –∏ –¥—Ä—É–≥–∏–µ
"""
import logging
from typing import Optional
from envparse import env
from langchain_openai import ChatOpenAI

logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
env.read_envfile(".env")


class OpenRouterLLM:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ª—é–±—ã–º–∏ LLM —á–µ—Ä–µ–∑ OpenRouter"""

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenRouter –∫–ª–∏–µ–Ω—Ç–∞"""
        self.api_key = env.str("OPENROUTER_API_KEY", default=None)
        self.base_url = "https://openrouter.ai/api/v1"

        if not self.api_key:
            logger.error("OPENROUTER_API_KEY not found in .env file")
            raise ValueError("OPENROUTER_API_KEY is required")

        logger.info("Initialized OpenRouter LLM service")

    def get_model(
        self,
        model_name: str,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
        **kwargs
    ):
        """
        –°–æ–∑–¥–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç LLM –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ OpenRouter

        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "anthropic/claude-3.5-sonnet")
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (0.0-1.0)
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ (None = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–æ–¥–µ–ª–∏

        Returns:
            ChatOpenAI –º–æ–¥–µ–ª—å —Å OpenRouter endpoint
        """
        try:
            # –°–æ–∑–¥–∞—ë–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
            model_params = {
                "model": model_name,
                "temperature": temperature,
                "api_key": self.api_key,
                "base_url": self.base_url,
                **kwargs
            }

            # –î–æ–±–∞–≤–ª—è–µ–º max_tokens —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
            if max_tokens is not None:
                model_params["max_tokens"] = max_tokens

            model = ChatOpenAI(**model_params)

            logger.info(f"Created model: {model_name} (temp={temperature}, max_tokens={max_tokens or 'unlimited'})")
            return model

        except Exception as e:
            logger.error(f"Error creating model {model_name}: {e}")
            return None


# Singleton instance
_openrouter_llm = None


def get_openrouter_service() -> OpenRouterLLM:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç singleton instance OpenRouterLLM"""
    global _openrouter_llm
    if _openrouter_llm is None:
        _openrouter_llm = OpenRouterLLM()
    return _openrouter_llm


def get_claude_model(
    model_name: str = "anthropic/claude-sonnet-4.5",
    temperature: float = 0.7,
    max_tokens: Optional[int] = None
):
    """
    –°–æ–∑–¥–∞–µ—Ç Claude –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ OpenRouter

    Args:
        model_name: –í–µ—Ä—Å–∏—è Claude (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: claude-4.5-sonnet)
        temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ (None = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)

    Returns:
        LLM –º–æ–¥–µ–ª—å
    """
    service = get_openrouter_service()
    return service.get_model(model_name, temperature, max_tokens)


def get_openai_model(
    model_name: str = "openai/gpt-4o-mini",
    temperature: float = 0.7,
    max_tokens: Optional[int] = None
):
    """
    –°–æ–∑–¥–∞–µ—Ç OpenAI –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ OpenRouter

    Args:
        model_name: –í–µ—Ä—Å–∏—è GPT (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: gpt-4o-mini)
        temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ (None = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)

    Returns:
        LLM –º–æ–¥–µ–ª—å
    """
    service = get_openrouter_service()
    return service.get_model(model_name, temperature, max_tokens)


def get_fast_model():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±—ã—Å—Ç—Ä—É—é –∏ –¥–µ—à–µ–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á (–∞–Ω–∞–ª–∏–∑, –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Ü–∏—Ç–∞—Ç)

    Returns:
        –ë—ã—Å—Ç—Ä–∞—è LLM –º–æ–¥–µ–ª—å (Claude 4.5 Haiku) –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ —Ç–æ–∫–µ–Ω–∞–º
    """
    model_name = env.str("FAST_MODEL", default="anthropic/claude-haiku-4.5")
    logger.info(f"Using fast model: {model_name}")
    return get_claude_model(model_name=model_name, temperature=0.3, max_tokens=None)


def get_smart_model(use_reasoning: bool = False):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–º–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞, –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏–µ)

    Args:
        use_reasoning: –í–∫–ª—é—á–∏—Ç—å extended thinking (reasoning) –¥–ª—è –º–æ–¥–µ–ª–∏

    Returns:
        –ú–æ—â–Ω–∞—è LLM –º–æ–¥–µ–ª—å (Claude 4.5 Sonnet) –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ —Ç–æ–∫–µ–Ω–∞–º
    """
    model_name = env.str("SMART_MODEL", default="anthropic/claude-sonnet-4.5")
    logger.info(f"Using smart model: {model_name} (reasoning={use_reasoning})")

    if use_reasoning:
        # Add reasoning parameter via model_kwargs
        service = get_openrouter_service()
        return service.get_model(
            model_name=model_name,
            temperature=0.7,
            max_tokens=None,
            model_kwargs={
                "extra_body": {
                    "reasoning": {
                        "max_tokens": 2000
                    }
                }
            }
        )
    else:
        return get_claude_model(model_name=model_name, temperature=0.7, max_tokens=None)


def get_writer_model():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤

    Returns:
        Writer LLM –º–æ–¥–µ–ª—å (Claude 4.5 Sonnet) –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ —Ç–æ–∫–µ–Ω–∞–º
    """
    model_name = env.str("WRITER_MODEL", default="anthropic/claude-sonnet-4.5")
    logger.info(f"Using writer model: {model_name}")
    return get_claude_model(model_name=model_name, temperature=0.7, max_tokens=None)


def get_analyzer_model():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞

    Returns:
        Analyzer LLM –º–æ–¥–µ–ª—å (Claude 4.5 Haiku) –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ —Ç–æ–∫–µ–Ω–∞–º
    """
    model_name = env.str("ANALYZER_MODEL", default="anthropic/claude-haiku-4.5")
    logger.info(f"Using analyzer model: {model_name}")
    return get_claude_model(model_name=model_name, temperature=0.3, max_tokens=None)


def get_custom_model(model_name: str, temperature: float = 0.7, max_tokens: Optional[int] = None):
    """
    –°–æ–∑–¥–∞–µ—Ç –∫–∞—Å—Ç–æ–º–Ω—É—é –º–æ–¥–µ–ª—å

    Args:
        model_name: –ü–æ–ª–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ OpenRouter
        temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
        max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ (None = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)

    Returns:
        LLM –º–æ–¥–µ–ª—å
    """
    service = get_openrouter_service()
    return service.get_model(model_name, temperature, max_tokens)


# –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏
AVAILABLE_MODELS = {
    # Anthropic Claude
    "claude-3.5-sonnet": "anthropic/claude-3.5-sonnet",
    "claude-3-opus": "anthropic/claude-3-opus",
    "claude-3-sonnet": "anthropic/claude-3-sonnet",
    "claude-3-haiku": "anthropic/claude-3-haiku",

    # OpenAI GPT
    "gpt-4o": "openai/gpt-4o",
    "gpt-4o-mini": "openai/gpt-4o-mini",
    "gpt-4-turbo": "openai/gpt-4-turbo",
    "gpt-3.5-turbo": "openai/gpt-3.5-turbo",

    # Google Gemini
    "gemini-2.0-flash": "google/gemini-2.0-flash-exp:free",
    "gemini-pro": "google/gemini-pro",

    # Meta Llama
    "llama-3.1-405b": "meta-llama/llama-3.1-405b-instruct",
    "llama-3.1-70b": "meta-llama/llama-3.1-70b-instruct",

    # Mistral
    "mistral-large": "mistralai/mistral-large",
    "mixtral-8x7b": "mistralai/mixtral-8x7b-instruct",
}


def list_available_models():
    """–í—ã–≤–æ–¥–∏—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    print("\nü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ OpenRouter:\n")
    for name, full_name in AVAILABLE_MODELS.items():
        print(f"  ‚Ä¢ {name:20} ‚Üí {full_name}")
    print()
